# GuÃ­a Completa de InstalaciÃ³n, EjecuciÃ³n y Pruebas de OMPar

## Tabla de Contenidos
- [DescripciÃ³n General](#descripciÃ³n-general)
- [Requisitos del Sistema](#requisitos-del-sistema)
- [InstalaciÃ³n Paso a Paso](#instalaciÃ³n-paso-a-paso)
- [ConversiÃ³n del Modelo](#conversiÃ³n-del-modelo)
- [EjecuciÃ³n](#ejecuciÃ³n)
- [Pruebas y ValidaciÃ³n](#pruebas-y-validaciÃ³n)
- [SoluciÃ³n de Problemas](#soluciÃ³n-de-problemas)
- [Estructura del Proyecto](#estructura-del-proyecto)

---

## DescripciÃ³n General

**OMPar** es una herramienta de compilaciÃ³n orientada a compiladores diseÃ±ada para identificar y generar oportunidades de paralelizaciÃ³n para cÃ³digo serial utilizando IA. El sistema consta de dos componentes principales:

1. **OMPify**: Detecta oportunidades de paralelizaciÃ³n en cÃ³digo
2. **MonoCoder**: Genera los pragmas OpenMP apropiados cuando se identifica que un bucle for se beneficiarÃ­a de la paralelizaciÃ³n

### Paper Asociado
**TÃ­tulo**: OMPar: Automatic Parallelization with AI-Driven Source-to-Source Compilation

### Rendimiento
En el conjunto de pruebas HeCBench (770 bucles), OMPar logra:
- **74%** de precisiÃ³n en predicciÃ³n de pragmas
- **86%** de precisiÃ³n con verificaciÃ³n de compilaciÃ³n y ejecuciÃ³n
- Supera significativamente a AutoPar (56%) e ICPC (62%)

---

## Requisitos del Sistema

### Hardware
- **GPU**: NVIDIA con soporte CUDA (recomendado para mejor rendimiento)
- **RAM**: MÃ­nimo 16 GB (recomendado 32 GB)
- **Almacenamiento**: ~10 GB de espacio libre

### Software
- **Sistema Operativo**: Linux (probado en Ubuntu 24.04)
- **Python**: 3.11 o 3.12
- **CUDA**: 12.1 o superior (probado con CUDA 13.0)
- **Git**: Para clonar repositorios

### VerificaciÃ³n de Requisitos

```bash
# Verificar Python
python3 --version
# Salida esperada: Python 3.12.x o 3.11.x

# Verificar CUDA
nvcc --version
# Salida esperada: Cuda compilation tools, release 12.1 o superior

# Verificar pip
pip3 --version
```

---

## InstalaciÃ³n Paso a Paso

### 1. Clonar el Repositorio

```bash
git clone https://github.com/Scientific-Computing-Lab/OMPar
cd OMPar
```

### 2. Instalar Dependencias del Sistema

```bash
# Instalar python3-venv (necesario para crear entornos virtuales)
sudo apt update
sudo apt install -y python3.12-venv
```

### 3. Crear Entorno Virtual

```bash
# Crear entorno virtual
python3 -m venv ompar_env

# Activar entorno virtual
source ompar_env/bin/activate
```

> **Nota**: Siempre debes activar el entorno virtual antes de usar OMPar.

### 4. Actualizar pip

```bash
pip install --upgrade pip
```

### 5. Instalar PyTorch con Soporte CUDA

```bash
# Instalar PyTorch 2.5.1 con CUDA 12.1
pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

> **Importante**: PyTorch 2.5.1 es la versiÃ³n mÃ¡s reciente compatible con CUDA 12.1. Versiones anteriores tienen vulnerabilidades de seguridad.

### 6. Instalar Dependencias de Python

```bash
# Instalar paquetes principales
pip install transformers datasets tokenizers huggingface_hub safetensors tqdm requests pyyaml regex nvidia-tensorrt

# Instalar tree-sitter versiÃ³n especÃ­fica
pip install tree-sitter==0.20.4
```

> **CrÃ­tico**: Debe ser tree-sitter 0.20.4 exactamente. Versiones mÃ¡s recientes tienen cambios incompatibles en la API.

### 7. Compilar el Parser

```bash
cd parser

# Eliminar versiÃ³n anterior si existe
rm -rf vendor/tree-sitter-c-sharp

# Clonar tree-sitter-c-sharp versiÃ³n compatible
cd vendor
git clone https://github.com/tree-sitter/tree-sitter-c-sharp
cd tree-sitter-c-sharp
git checkout v0.20.0
cd ../..

# Compilar el parser
source ../ompar_env/bin/activate
python build.py

# Verificar que se creÃ³ el archivo
ls -lh my-languages.so
# Salida esperada: -rwxrwxr-x ... 4.9M ... my-languages.so
```

### 8. Descargar Pesos del Modelo OMPify

Los pesos del modelo no estÃ¡n incluidos en el repositorio. DescÃ¡rgalos desde:

**Google Drive**: [OMPify Weights](https://drive.google.com/drive/folders/1tnJf9YvjpDLktVi23TkW-rpjqfdZoybf?usp=sharing)

```bash
# Descomprimir en el directorio 'model'
cd /home/antony/Desktop/paper/OMPar
# AsegÃºrate de que la estructura sea:
# model/
# â”œâ”€â”€ data/
# â”‚   â”œâ”€â”€ 0
# â”‚   â”œâ”€â”€ 1
# â”‚   â””â”€â”€ ... (205 archivos)
# â”œâ”€â”€ data.pkl
# â””â”€â”€ version
```

---

## ConversiÃ³n del Modelo

El modelo OMPify se descarga en formato distribuido de PyTorch. Necesitas convertirlo a `model.bin` para su uso:

### Script de ConversiÃ³n

El script `convert_model.py` ya estÃ¡ incluido en el repositorio. EjecÃºtalo:

```bash
source ompar_env/bin/activate
python convert_model.py
```

**Salida esperada:**
```
Loading model from model...
âœ“ Model loaded successfully!
  Type: <class 'collections.OrderedDict'>
  Number of parameters: 205
  Sample keys: ['encoder.roberta.embeddings.word_embeddings.weight', ...]

âœ“ Saved model to model/model.bin
  File size: 477.82 MB
```

### VerificaciÃ³n

```bash
ls -lh model/model.bin
# Salida esperada: -rw-rw-r-- ... 477M ... model.bin
```

### (Opcional) GeneraciÃ³n de Engine TensorRT

Para habilitar la aceleraciÃ³n mÃ¡xima (Fase 3), debes generar el motor de TensorRT. Esto crearÃ¡ un archivo optimizado para tu GPU especÃ­fica.

```bash
# Ejecutar conversiÃ³n a TensorRT (requiere GPU NVIDIA)
python cpp_extensions/monocoder_tensorrt/convert_to_trt.py
```

**Salida esperada:**
```
ðŸš€ CONVERTIR MONOCODER A TENSORRT (FIXED SHAPE)
...
âœ… Engine TensorRT guardado: cpp_extensions/monocoder_tensorrt/monocoder_fixed.engine
âœ… Inferencia exitosa!
```

---

## Modificaciones de CÃ³digo Necesarias

### Â¿Por quÃ© son necesarias?

PyTorch 2.5.1 tiene restricciones de seguridad que requieren PyTorch 2.6+ para cargar modelos en formato pickle. Como PyTorch 2.6+ no estÃ¡ disponible para CUDA 12.1, usamos el formato safetensors.

### 1. Modificar `OMPify/model.py`

**LÃ­neas 130-133**, cambiar:
```python
model = RobertaForSequenceClassification.from_pretrained(base_model, config=self.config)    
self.model=Model(model,self.config,self.tokenizer)
self.model.load_state_dict(torch.load(os.path.join(model_path, 'model.bin')))
```

**Por:**
```python
# Use safetensors to avoid PyTorch 2.6+ requirement
model = RobertaForSequenceClassification.from_pretrained(base_model, config=self.config, use_safetensors=True)    
self.model=Model(model,self.config,self.tokenizer)
self.model.load_state_dict(torch.load(os.path.join(model_path, 'model.bin'), weights_only=True))
```

### 2. Modificar `compAI.py`

**LÃ­nea 14**, cambiar:
```python
self.model_gen = GPTNeoXForCausalLM.from_pretrained('MonoCoder/MonoCoder_OMP').to(device)
```

**Por:**
```python
self.model_gen = GPTNeoXForCausalLM.from_pretrained('MonoCoder/MonoCoder_OMP', use_safetensors=True).to(device)
```

> **Nota**: Estas modificaciones ya estÃ¡n aplicadas si seguiste esta guÃ­a.

---

## EjecuciÃ³n

### Activar Entorno

Siempre activa el entorno virtual antes de ejecutar OMPar:

```bash
cd /home/antony/Desktop/paper/OMPar
source ompar_env/bin/activate
```

### Ejecutar Casos de Uso de Ejemplo

```bash
python run_ompar.py --model_weights model
```

### Uso ProgramÃ¡tico

```python
import torch
from compAI import OMPAR
import argparse

# Configurar argumentos
parser = argparse.ArgumentParser()
parser.add_argument('--vocab_file', default='tokenizer/gpt/gpt_vocab/gpt2-vocab.json')
parser.add_argument('--merge_file', default='tokenizer/gpt/gpt_vocab/gpt2-merges.txt')
parser.add_argument('--model_weights', default='model')
args = parser.parse_args([])

# Inicializar OMPar
device = 'cuda' if torch.cuda.is_available() else 'cpu'
ompar = OMPAR(model_path=args.model_weights, device=device, args=args)

# Analizar cÃ³digo
code = """for(int i = 0; i < 1000; i++){
    sum += array[i];
}"""

pragma = ompar.auto_comp(code)
if pragma:
    print(f"Pragma sugerido: #pragma {pragma}")
else:
    print("No se requiere paralelizaciÃ³n")
```

---

## Pruebas y ValidaciÃ³n

### Casos de Prueba Incluidos

El archivo `use_cases.jsonl` contiene 7 casos de prueba:

#### 1. Bucle Paralelo Simple âœ…
```c
for (int i = 0; i < size; i++) {
    array[i] = compute(array[i]);
}
```
- **Esperado**: `#pragma omp parallel for`
- **Predicho**: `#pragma omp parallel for` âœ“

#### 2. Suma de Arrays âœ…
```c
for (int i = 0; i < size; i++) {
    result[i] = array1[i] + array2[i];
}
```
- **Esperado**: `#pragma omp parallel for`
- **Predicho**: `#pragma omp parallel for` âœ“

#### 3. ReducciÃ³n âœ…
```c
for (int i = 0; i < size; i++) {
    sum += array[i];
}
```
- **Esperado**: `#pragma omp parallel for reduction(+:sum)`
- **Predicho**: `#pragma omp parallel for reduction( + :sum)` âœ“

#### 4. Diagonal de Matriz âš ï¸
```c
for (int i = 0; i < size; i++) {
    matrix[i][i] = value;
}
```
- **Esperado**: `#pragma omp parallel for`
- **Predicho**: (vacÃ­o) - Falso negativo

#### 5. MultiplicaciÃ³n por Escalar âœ…
```c
for (int i = 0; i < size; i++) {
    temp[i] = array[i] * factor;
}
```
- **Esperado**: `#pragma omp parallel for`
- **Predicho**: `#pragma omp parallel for` âœ“

#### 6. Early Return (No Paralelizable) âœ…
```c
for (int i = 0; i < size; i++) {
    if (array[i] < 0) {
        return i;
    }
}
```
- **Esperado**: (vacÃ­o)
- **Predicho**: (vacÃ­o) âœ“

#### 7. Dependencia de Datos (No Paralelizable) âœ…
```c
for (int i = 0; i < size; i++) {
    array[i] = array[i - 1] + array[i + 1];
}
```
- **Esperado**: (vacÃ­o)
- **Predicdo**: (vacÃ­o) âœ“

### Resultados de las Pruebas

**PrecisiÃ³n**: 6/7 (85.7%)
- âœ… Verdaderos Positivos: 4
- âœ… Verdaderos Negativos: 2
- âš ï¸ Falsos Negativos: 1
- âœ… Falsos Positivos: 0

### Ejecutar Pruebas Personalizadas

Crea un archivo `custom_tests.jsonl`:

```json
{"code": "for (int i = 0; i < n; i++) { a[i] = b[i] + c[i]; }", "label": true, "pragma": "#pragma omp parallel for"}
{"code": "for (int i = 1; i < n; i++) { a[i] = a[i-1] + 1; }", "label": false, "pragma": ""}
```

Modifica `run_ompar.py` para usar tu archivo:

```python
with open('custom_tests.jsonl', 'r') as f:
    # ... resto del cÃ³digo
```

---

## SoluciÃ³n de Problemas

### Error: `conda: command not found`

**SoluciÃ³n**: Usar `venv` en lugar de conda (ya implementado en esta guÃ­a).

### Error: `tree-sitter` versiÃ³n incompatible

```
ValueError: Incompatible Language version 15. Must be between 13 and 14
```

**SoluciÃ³n**:
```bash
cd parser/vendor
rm -rf tree-sitter-c-sharp
git clone https://github.com/tree-sitter/tree-sitter-c-sharp
cd tree-sitter-c-sharp
git checkout v0.20.0
cd ../..
python build.py
```

### Error: PyTorch 2.6+ requerido

```
ValueError: Due to a serious vulnerability issue in `torch.load`...
```

**SoluciÃ³n**: Aplicar las modificaciones de cÃ³digo descritas en la secciÃ³n [Modificaciones de CÃ³digo Necesarias](#modificaciones-de-cÃ³digo-necesarias).

### Error: CUDA out of memory

**SoluciÃ³n**: Reducir el tamaÃ±o del batch o usar CPU:

```python
device = 'cpu'  # Forzar uso de CPU
```

### Warnings sobre `attention_mask`

```
The attention mask and the pad token id were not set...
```

**SoluciÃ³n**: Estos warnings son normales y no afectan la funcionalidad. Puedes ignorarlos.

---

## Estructura del Proyecto

```
OMPar/
â”œâ”€â”€ ompar_env/                    # Entorno virtual Python
â”œâ”€â”€ parser/
â”‚   â”œâ”€â”€ my-languages.so          # Parser compilado (4.9 MB)
â”‚   â”œâ”€â”€ vendor/
â”‚   â”‚   â””â”€â”€ tree-sitter-c-sharp/ # v0.20.0
â”‚   â”œâ”€â”€ build.py
â”‚   â””â”€â”€ build.sh
â”œâ”€â”€ OMPify/
â”‚   â”œâ”€â”€ model.py                 # Modelo de clasificaciÃ³n
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ data/                    # Pesos distribuidos (205 archivos)
â”‚   â”œâ”€â”€ data.pkl                 # Ãndice del modelo
â”‚   â”œâ”€â”€ model.bin                # Modelo convertido (477.82 MB)
â”‚   â””â”€â”€ version
â”œâ”€â”€ tokenizer/
â”‚   â””â”€â”€ gpt/
â”‚       â””â”€â”€ gpt_vocab/
â”‚           â”œâ”€â”€ gpt2-vocab.json
â”‚           â””â”€â”€ gpt2-merges.txt
â”œâ”€â”€ evaluation/                  # Scripts de evaluaciÃ³n
â”œâ”€â”€ compAI.py                    # Clase principal OMPAR
â”œâ”€â”€ run_ompar.py                 # Script de ejecuciÃ³n
â”œâ”€â”€ convert_model.py             # Script de conversiÃ³n de modelo
â”œâ”€â”€ use_cases.jsonl              # Casos de prueba
â”œâ”€â”€ requirements.txt             # Dependencias simplificadas
â”œâ”€â”€ environment.yml              # Entorno conda original
â”œâ”€â”€ README.md                    # README original
â””â”€â”€ INSTALLATION_GUIDE.md        # Esta guÃ­a
```

---

## InformaciÃ³n Adicional

### Modelos Utilizados

1. **OMPify**: 
   - Base: `microsoft/graphcodebert-base`
   - TamaÃ±o: 477.82 MB
   - PropÃ³sito: ClasificaciÃ³n de paralelizaciÃ³n

2. **MonoCoder**:
   - Base: `MonoCoder/MonoCoder_OMP`
   - TamaÃ±o: 3.59 GB
   - PropÃ³sito: GeneraciÃ³n de pragmas

### Recursos del Sistema Durante la EjecuciÃ³n

- **Memoria GPU**: ~8-10 GB (con CUDA)
- **Memoria RAM**: ~6-8 GB
- **Tiempo de carga inicial**: ~30-60 segundos
- **Tiempo por predicciÃ³n**: ~2-5 segundos

### Licencia

MIT License - Ver archivo LICENSE en el repositorio

### Citas

Si usas OMPar en tu investigaciÃ³n, por favor cita:

```bibtex
@article{ompar2024,
  title={OMPar: Automatic Parallelization with AI-Driven Source-to-Source Compilation},
  author={...},
  journal={...},
  year={2024}
}
```

### Contacto y Soporte

- **Repositorio**: https://github.com/Scientific-Computing-Lab/OMPar
- **Issues**: https://github.com/Scientific-Computing-Lab/OMPar/issues

---

## Resumen de Comandos RÃ¡pidos

```bash
# InstalaciÃ³n completa
git clone https://github.com/Scientific-Computing-Lab/OMPar
cd OMPar
sudo apt install -y python3.12-venv
python3 -m venv ompar_env
source ompar_env/bin/activate
pip install --upgrade pip
pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers datasets tokenizers huggingface_hub safetensors tqdm requests pyyaml regex tree-sitter==0.20.4 nvidia-tensorrt

# Compilar parser
cd parser
rm -rf vendor/tree-sitter-c-sharp
cd vendor && git clone https://github.com/tree-sitter/tree-sitter-c-sharp && cd tree-sitter-c-sharp && git checkout v0.20.0 && cd ../..
python build.py
cd ..

# Convertir modelo (despuÃ©s de descargar pesos)
python convert_model.py

# (Opcional) Generar Engine TensorRT para mÃ¡ximo rendimiento
python cpp_extensions/monocoder_tensorrt/convert_to_trt.py

# Ejecutar
python run_ompar.py --model_weights model
```

---

**Ãšltima actualizaciÃ³n**: 4 de enero de 2026  
**VersiÃ³n de la guÃ­a**: 1.0  
**Sistema probado**: Ubuntu 24.04, Python 3.12.3, CUDA 13.0
